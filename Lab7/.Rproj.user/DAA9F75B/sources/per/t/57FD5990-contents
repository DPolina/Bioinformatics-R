if (!requireNamespace("stringdist", quietly = TRUE)) install.packages("stringdist")
library(stringdist)
library(ggplot2)

# 1. Загрузка данных
file_path <- "data2.txt"
data <- as.matrix(read.table(file_path, stringsAsFactors = FALSE))
head(data)

# 2. Формирование матрицы расстояний D2 (используем меру оптимального выравнивания)
n <- nrow(data)
D2 <- matrix(0, n, n)  # Матрица расстояний

for (i in 1:n) {
  for (j in 1:n) {
    D2[i, j] <- stringdist(data[i, ], data[j, ], method = "osa")^2
  }
}
print("Матрица квадратов расстояний D2:")
print(D2)

# Мера оптимального выравнивания (osa) определяет минимальную стоимость 
# преобразований (вставка, удаление, замена и транспозиция).

# 3. Вычисление матрицы G (двойное центрирование матрицы D2)
#H <- diag(n) - (1 / n) * matrix(1, n, n)  # Центрирующая матрица (средние значения по столбцам и строкам равны 0)
#G <- -0.5 * H %*% D2 %*% H
D2_j <- colMeans(D2)  # Средние по столбцам
D2_i <- rowMeans(D2)  # Средние по строкам
D2_all <- mean(D2)    # Общее среднее значение

G <- matrix(0, n, n)
for (i in 1:n) {
  for (j in 1:n) {
    G[i, j] <- - 0.5 * (D2_all - D2_j[j] - D2_i[i] + D2[i, j])
  }
}
print("Матрица G:")
print(G)

# Вычисляем средние значения по строкам и столбцам
mean_rows <- rowMeans(G)
mean_cols <- colMeans(G)

# Проверка равенства средних значений нулю
cat("Средние значения по строкам матрицы G:\n")
print(mean_rows)
cat("Средние значения по столбцам матрицы G:\n")
print(mean_cols)
cat("Среднее значение всех элементов матрицы G:\n")
print(mean(G))

# 4. Степенной метод для нахождения первых N собственных значений и векторов.

# Идея степенного метода состоит в последовательном итерационном нахождении максимальных 
# собственных значений (lambda) и векторов (v) матрицы G, воспользовавшись свойствами 
# ортогональности собственных векторов и симметричности матрицы G.

# Степенной метод используется для приближённого нахождения собственных значений матрицы. 
# Основная идея заключается в том, что повторное умножение произвольного вектора на 
# матрицу (в пределе) приближает его к собственному вектору, который соответствует 
# наибольшему по модулю собственному значению.
N <- 30
power_method <- function(matrix, N, max_iter = 1000, tol = 1e-6) {
  n <- nrow(matrix)  # Размер матрицы
  eigenvalues <- c()  # Пустой вектор для хранения собственных значений
  eigenvectors <- list()  # Список для хранения собственных векторов
  B <- matrix  # Создаём копию матрицы, с которой будем работать
  
  for (k in 1:N) {  # Цикл для поиска N собственных значений и векторов
    v <- runif(n)  # Шаг 1. Инициализация случайного начального вектора v
    v <- v / sqrt(sum(v^2))  # Нормировка вектора: делим на его длину
    lambda_old <- 0  # Начальное значение для проверки сходимости
    
    # Шаг 2. Итерационный процесс для нахождения максимального собственного значения
    for (i in 1:max_iter) {
      w <- B %*% v  # Умножаем матрицу B на вектор v
      lambda <- sum(w * v)  # Собственное значение как скалярное произведение: λ ≈ v^T * B * v
      v <- w / sqrt(sum(w^2))  # Нормировка вектора w
      if (abs(lambda - lambda_old) < tol) break  # Проверка сходимости по изменению λ
      lambda_old <- lambda  # Обновляем значение λ для следующей итерации
    }
    
    # Шаг 3. Сохранение результатов
    eigenvalues <- c(eigenvalues, lambda)  # Добавляем найденное собственное значение
    eigenvectors[[k]] <- v  # Сохраняем соответствующий собственный вектор
    
    # Шаг 4. Дефляция матрицы для поиска следующего собственного значения
    B <- B - lambda * (v %*% t(v))  # Вычитаем вклад текущего собственного вектора
  }
  
  list(values = eigenvalues, vectors = eigenvectors)  # Возвращаем список результатов
}

# Применяем степенной метод
eigen_results <- power_method(G, N) 
eigenvalues <- eigen_results$values # Собственные значения
eigenvectors <- eigen_results$vectors # Собственные векторы

cat("Первые ", N, " собственных значений:")
print(eigenvalues)

# 5. Рассчет проекции объектов на оси главных координат

# Проекции — это преобразованные координаты объектов в новом пространстве (первая и вторая главные координаты).

M <- 2  # Число главных координат
projections <- matrix(0, n, M)
for (j in 1:M) {
  projections[, j] <- sqrt(eigenvalues[j]) * eigenvectors[[j]]
}

print("Проекции объектов на первые 2 главные координаты:")
print(projections)

# 6. Построение диаграммы рассеяния
load("clusters.RData")

df <- data.frame(X = projections[, 1], Y = projections[, 2], Cluster = as.factor(clusters))
ggplot(df, aes(x = X, y = Y, color = Cluster)) +
  geom_point(size = 3) +
  labs(title = "Диаграмма рассеяния на первых двух главных координатах",
       x = "Главная координата 1",
       y = "Главная координата 2") +
  theme_minimal()

# 7. Построение графика зависимости собственных значений от порядкового номера
df_eigen <- data.frame(Index = 1:N, Eigenvalue = eigenvalues[1:N])
ggplot(df_eigen, aes(x = Index, y = Eigenvalue)) +
  geom_line() +
  geom_point(size = 3) +
  labs(title = "Зависимость собственных значений от порядкового номера",
       x = "Номер главной координаты",
       y = "Собственное значение") +
  theme_minimal()

# График показывает, как собственные значения уменьшаются. Это помогает определить важность каждой координаты.

# 8. Определение оптимального числа главных координат

# Определим оптимальное число как число координат, при котором сумма собственных 
# значений достигает 95% от общей суммы.
cumulative_variance <- cumsum(eigenvalues) / sum(eigenvalues)
optimal_M <- which(cumulative_variance >= 0.95)[1]
print(paste("Оптимальное число главных координат:", optimal_M))

# 9. Рассчет доли разброса для первых двух главных компонент
total_eigenvalues <- sum(eigenvalues)  # Сумма всех собственных значений
eigenvalues_2 <- sum(eigenvalues[1:2])  # Сумма первых двух собственных значений
fraction <- eigenvalues_2 / total_variance  # Доля разброса

cat("Доля разброса на первые две главные компоненты:", round(fraction * 100, 2), "%\n")

